# -*- coding: utf-8 -*-
"""Intro2BA_final_Team13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wdmXUqKV2xk7kxpgRbcUFeBI8b9mMHfL

# Set Up
"""

# Commented out IPython magic to ensure Python compatibility.
##for diff versions of Python
from __future__ import division, print_function, unicode_literals

##importing data
import pandas as pd
import numpy as np

# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap

##building models and hyper parameter tuning
np.random.seed(42)
from sklearn.preprocessing import LabelEncoder
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

from warnings import simplefilter
from sklearn.exceptions import ConvergenceWarning
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, classification_report

## Learning Curve
from sklearn.model_selection import learning_curve
from sklearn.model_selection import ShuffleSplit
import matplotlib.pyplot as plt

## Fitting Graph
from sklearn.model_selection import train_test_split
from sklearn.model_selection import validation_curve

## ROC Curve
from sklearn.metrics import roc_curve, auc

from google.colab import files
uploaded = files.upload()

"""# Import Data"""

df = pd.read_csv("UCI_Credit_Card.csv")

df.head()

"""# EDA"""

df.describe()

total = df.isnull().sum().sort_values(ascending = False)
print(total)

## skewness
skew_value = df.skew(axis=0)
list_skew_value = list(skew_value)
c = 0
for s in list_skew_value:
  if s > 0.8:
    c += 1
print('Number of columns with skewness > 0.8: '+ str(c))

"""## distributions"""

df1 = df.iloc[:, 1:]
df1.columns

# Distribution
fig = plt.figure(figsize=(240, 90))
ax = fig.gca()
fig_1 = df1.hist(ax=ax, layout=(3,8), xlabelsize=35, ylabelsize=35, bins=50)
[x.title.set_size(40) for x in fig_1.ravel()]
plt.show()

"""## closer inspections"""

temp = df["default.payment.next.month"].value_counts()
df_1 = pd.DataFrame({'default.payment.next.month': temp.index,'count': temp.values})
plt.figure(figsize = (6,6))
plt.title('Default Credit Card Clients - target value - data unbalance\n (Not Default = 0, Default = 1)')
sns.set_color_codes("pastel")
sns.barplot(x = 'default.payment.next.month', y="count", data=df_1)
locs, labels = plt.xticks()
plt.show()



a4_dims = (14, 6)
fig, ax = plt.subplots(figsize=a4_dims)
sns.countplot(df['AGE'],ax=ax, color="#357AD1")
plt.xticks(rotation = 45)

"""NOTE: Count of defaults vs. Age is normally distributed w/ a right skew"""

a5_dims = (65, 10)
fig, ax = plt.subplots(figsize=a5_dims)
sns.countplot(df['LIMIT_BAL'],ax=ax, color="#357AD1")
plt.xticks(rotation = 45)

df['LIMIT_BAL'].value_counts().head(5)

list(df)

df['SEX'].unique()
df['EDUCATION'].unique()
df['PAY_5'].unique()

"""## Corr Matrix"""

from typing import ChainMap


plt.figure(figsize = (30,20))
plt.xticks(size = 15)
plt.yticks(size = 15)
sns.heatmap(df.corr(), center= 0.0, annot = True, cmap="vlag")
plt.show()

"""# Oversampling"""

X = df.loc[:, ~df.columns.isin(['ID','default.payment.next.month'])]
y = df['default.payment.next.month']

#oversampling all
from imblearn.over_sampling import RandomOverSampler
from collections import Counter

print('Original dataset shape %s' % Counter(y))

# Documentation https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html
ros = RandomOverSampler(random_state=42) # default sampling strategy: resample all classes but the majority class
X_oversampled, y_oversampled = ros.fit_resample(X, y)

print('Resampled dataset shape %s' % Counter(y_oversampled))

#oversampling
from imblearn.over_sampling import RandomOverSampler
from collections import Counter
print('Original dataset shape %s' % Counter(y))

ros = RandomOverSampler(random_state=42,
                        sampling_strategy=0.7)
X_oversampled, y_oversampled = ros.fit_resample(X, y)

print('Resampled dataset shape %s' % Counter(y_oversampled))

"""# Feture selection (no use, reduced the performance of LR)

## 1. DT model
"""

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_oversampled,y_oversampled)

scores = cross_val_score(dt, X_oversampled, y_oversampled, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

from sklearn.feature_selection import SelectFromModel
print("Before feature selection: ", X.shape)

model = SelectFromModel(dt,prefit=True)
X1 = model.transform(X_oversampled)
print("After feature selection: ", X1.shape)

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X1,y_oversampled)

scores = cross_val_score(dt, X1, y_oversampled, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""## 2. KNN model"""

sc = StandardScaler()
sc.fit(X_oversampled)

knn = KNeighborsClassifier(p=2, metric='minkowski')

scores = cross_val_score(knn, X_oversampled, y_oversampled, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""## 3. LR model"""

from warnings import simplefilter

#To ignore the convergence warnings
simplefilter("ignore", category=ConvergenceWarning)

lr = LogisticRegression(random_state=42, solver='lbfgs')
lr.fit(X_oversampled, y_oversampled)

scores = cross_val_score(lr, X_oversampled, y_oversampled, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
print('Slope: %.3f', lr.coef_)                       # estimated coefficients for the linear regression model

from sklearn.feature_selection import SelectFromModel
print(X.shape)

model = SelectFromModel(lr,prefit=True)
X2 = model.transform(X_oversampled)
print(X2.shape)

lr = LogisticRegression(random_state=42, solver='liblinear')
lr.fit(X2, y_oversampled)

scores = cross_val_score(lr, X2, y_oversampled, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
print('Slope: %.3f', lr.coef_)                       # estimated coefficients for the linear regression model

"""# Feature Engineering

## FE1 (DT doesn't change, LR imporved by 0.2) -- use this
"""

# copy the dateset for feature engineering
df1 = df.copy()

# create new features
df1['BILL_AVG'] = df [['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].mean(axis=1)
df1.head()

# assign new X and y
X = df1.loc[:, ~df1.columns.isin(['ID','default.payment.next.month']+['BILL_AMT%s' % (i) for i in range(1,7)])]
y = df1['default.payment.next.month']
X.head()

"""oversampling"""

#oversampling all
from imblearn.over_sampling import RandomOverSampler
from collections import Counter

#oversampling 70% (we will use this)
print('Original dataset shape %s' % Counter(y))

ros = RandomOverSampler(random_state=42,
                        sampling_strategy=0.7) # default sampling strategy: resample all classes but the majority class
                                               # the float number corresponds to the desired ratio of the number of samples
                                               # in the minority class over the number of samples in the majority class after resampling.
X_oversampled_1, y_oversampled_1 = ros.fit_resample(X, y)

print('Resampled dataset shape %s' % Counter(y_oversampled_1))

"""### 1. DT model"""

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_oversampled_1,y_oversampled_1)

scores = cross_val_score(dt, X_oversampled_1, y_oversampled_1, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""### 2. kNN"""

sc = StandardScaler()
sc.fit(X_oversampled_1)

knn = KNeighborsClassifier(p=2, metric='minkowski')

scores = cross_val_score(knn, X_oversampled_1, y_oversampled_1, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""### 3. LR model"""

from warnings import simplefilter

#To ignore the convergence warnings
simplefilter("ignore", category=ConvergenceWarning)

lr = LogisticRegression(random_state=42, solver='lbfgs')
lr.fit(X_oversampled_1, y_oversampled_1)

scores = cross_val_score(lr, X_oversampled_1, y_oversampled_1, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
print('Slope: %.3f', lr.coef_)                       # estimated coefficients for the linear regression model

"""## FE2 (reduced the std of DT, reduced LR by 0.06)"""

# copy the dateset for feature engineering
df2 = df.copy()

# create new features
for i in range(1,7):
  df2['PAY_BILL_DIFF%s' % (i)] = df2['PAY_AMT%s' % (i)] - df2['BILL_AMT%s' % (i)]

# assign new X and y
X = df2.loc[:, ~df2.columns.isin(['ID','default.payment.next.month'] + ['BILL_AMT%s' % (i) for i in range(1,7)] + ['PAY_AMT%s' % (i) for i in range(1,7)])]
y = df2['default.payment.next.month']

X.head()

"""oversampling"""

#oversampling
from imblearn.over_sampling import RandomOverSampler
from collections import Counter

print('Original dataset shape %s' % Counter(y))

ros = RandomOverSampler(random_state=42,
                        sampling_strategy=0.7)
X_oversampled_2, y_oversampled_2 = ros.fit_resample(X, y)

print('Resampled dataset shape %s' % Counter(y_oversampled_2))

"""### 1. DT model"""

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_oversampled_2,y_oversampled_2)

scores = cross_val_score(dt, X_oversampled_2, y_oversampled_2, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""### 2. kNN"""

sc = StandardScaler()
sc.fit(X_oversampled_2)

knn = KNeighborsClassifier(p=2, metric='minkowski')

scores = cross_val_score(knn, X_oversampled_2, y_oversampled_2, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

"""### 3. LR model"""

from warnings import simplefilter

#To ignore the convergence warnings
simplefilter("ignore", category=ConvergenceWarning)

lr = LogisticRegression(random_state=42, solver='lbfgs')
lr.fit(X_oversampled_2, y_oversampled_2)

scores = cross_val_score(lr, X_oversampled_2, y_oversampled_2, cv=10, scoring='f1')

print("Performance: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
print('Slope: %.3f', lr.coef_)                       # estimated coefficients for the linear regression model

"""# Model Hypertuning

## 1. Decision Tree
"""

##Cross Validation
inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)   #inner cv folds
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)   #outter cv folds

gs_dt = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None],
                               'criterion':['gini','entropy'],
                               'min_samples_leaf':np.arange(1, 20, 2).tolist()}],
                  scoring='f1',
                  cv=inner_cv,
                  n_jobs=4)

gs_dt = gs_dt.fit(X_oversampled_1,y_oversampled_1)
print("\nParameter Tuning for Decision Tree")
print("Non-nested CV f1-score: ", gs_dt.best_score_)
print("Optimal Parameter: ", gs_dt.best_params_)
print("Optimal Estimator: ", gs_dt.best_estimator_)
nested_score_gs_dt = cross_val_score(gs_dt, X=X_oversampled_1, y=y_oversampled_1, cv=outer_cv)
print("Nested CV f1-score: ",nested_score_gs_dt.mean(), " +/- ", nested_score_gs_dt.std())

"""## 2. k-NN"""

pipe = Pipeline([
    ('sc', StandardScaler()),
    ('knn', KNeighborsClassifier(p=2,
                                 metric='minkowski'))
])

#Parameters to optimize:  k for number of nearest neighbors AND type of distance

params = {
        'knn__n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],
        'knn__weights': ['uniform', 'distance']
    }

gs_knn = GridSearchCV(estimator=pipe,
                  param_grid=params,
                  scoring='f1',
                  cv=inner_cv,
                  n_jobs=4)

gs_knn = gs_knn.fit(X_oversampled_1,y_oversampled_1)
print("\nParameter Tuning for kNN")
print("Non-nested CV f1-score: ", gs_knn.best_score_)
print("Optimal Parameter: ", gs_knn.best_params_)
print("Optimal Estimator: ", gs_knn.best_estimator_) # Estimator that was chosen by the search, i.e. estimator which gave highest score
nested_score_gs_knn = cross_val_score(gs_knn, X=X_oversampled_1, y=y_oversampled_1, cv=outer_cv)
print("Nested CV f1-score: ",nested_score_gs_knn.mean(), " +/- ", nested_score_gs_knn.std())

"""## 3. Logistic Regression"""

#To ignore the convergence warnings
simplefilter("ignore", category=ConvergenceWarning)

# Choosing C parameter for Logistic Regression AND type of penalty (ie., l1 vs l2)
gs_lr = GridSearchCV(estimator=LogisticRegression(random_state=42, solver='liblinear'),
                  param_grid=[{'C': [ 0.00001, 0.0001, 0.001, 0.01, 0.1 ,1 ,10 ,100, 1000, 10000, 100000, 1000000, 10000000],
                              'penalty':['l1','l2']}],
                  scoring='f1',

                  cv=inner_cv)

gs_lr = gs_lr.fit(X_oversampled_1,y_oversampled_1)
print("\nParameter Tuning for Logistic Regression")
print("Non-nested CV f1-score: ", gs_lr.best_score_)
print("Optimal Parameter: ", gs_lr.best_params_)
print("Optimal Estimator: ", gs_lr.best_estimator_)
nested_score_gs_lr = cross_val_score(gs_lr, X=X_oversampled_1, y=y_oversampled_1, cv=outer_cv)
print("Nested CV f1-score:",nested_score_gs_lr.mean(), " +/- ", nested_score_gs_lr.std())

"""# Model Evaluations

## Fitting Graphs
"""

clf_dt = DecisionTreeClassifier(criterion='entropy', random_state=42)
clf_knn = KNeighborsClassifier(weights='distance')
clf_lr = LogisticRegression(penalty='l1',random_state=42, solver='liblinear')
cv = ShuffleSplit(n_splits=10, test_size=0.20, random_state=42)

# Function for fitting graphs
def plot_fitting_curve(estimator, title, X, y,param_name,param_range,scoring_method, ylim=None, cv=None,
                        n_jobs=1):

    plt.figure()
    plt.grid()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Parameter "+param_name)
    plt.ylabel(scoring_method)

    train_scores, test_scores = validation_curve(estimator=estimator, X=X,y=y,param_name=param_name, param_range=param_range,cv=cv,scoring=scoring_method,n_jobs=4)
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)

    plt.plot(param_range, train_mean, color='blue', marker='o',markersize=5, label='training f1-score')
    plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')

    plt.plot(param_range, test_mean,color='green', linestyle='--', marker='s', markersize=5, label='validation f1-score')
    plt.fill_between(param_range,test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')

    plt.legend(loc='best')
    plt.tight_layout()
    return plt

"""### 1. Decision *Tree*"""

#decision tree
param_range = [i for i in range(1,61)]
plot_fitting_curve(clf_dt, "Fitting Curve for Decision Tree Classifier", X_oversampled_1, y_oversampled_1,
                   'max_depth',param_range,'f1', ylim=[0.5,1.02], cv=cv, n_jobs=4)
plt.show()

"""### 2. Fitting Graph (kNN)"""

from sklearn.neighbors import KNeighborsClassifier
param_range = [i for i in range(1,30)]
plot_fitting_curve(clf_knn, "Fitting Curve for kNN Classifier", X_oversampled_1, y_oversampled_1,
                   'n_neighbors', param_range,'f1', ylim=[0.7,1.02], cv=cv, n_jobs=4)
plt.show()

"""### 3. Fitting Graph (Logistic Regression)"""

# Fitting curve (aka validation curve)
# Determine training and test scores for varying parameter values.
from sklearn.model_selection import validation_curve
# Split validation
from sklearn.model_selection import train_test_split
# Class for Logistic Regression classifier
from sklearn.linear_model import LogisticRegression

np.random.seed(42)                        # the seed used by the random number generator for np

# Fitting Graph: Logistic Regression Classifier
param_range = [0.00001, 0.0001, 0.001, 0.01, 0.1 ,1 ,10 ,100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000]
plot_fitting_curve(clf_lr, "Fitting Curve for Logistic Regression Classifier", X_oversampled_1, y_oversampled_1,
                   'C', param_range,'f1', ylim=[0, 0.6], cv=cv, n_jobs=4)
plt.xscale('log')
plt.show()

"""## ROC"""

###################################### Classifier ######################################

X_train, X_test, y_train, y_test = train_test_split(X_oversampled_1,
                                                    y_oversampled_1,
                                                    test_size=0.20,
                                                    random_state=42)

# Commented out IPython magic to ensure Python compatibility.
######################################## Classifiers ########################################
# kNN Classifier

clf1 = Pipeline([
        ('sc', StandardScaler()),
        ('knn', KNeighborsClassifier(n_neighbors=21, weights='distance'))
      ])


# Decision Tree Classifier
clf2 = DecisionTreeClassifier(criterion='entropy',
                              min_samples_leaf=1,
                              random_state=42)

# Logistic Regression Classifier
clf3 = LogisticRegression(penalty='l1',
                          C=10,
                          random_state=42,
                          solver='liblinear')


# Label the classifiers
clf_labels = ['kNN', 'Decision tree', 'Logistic regression']
all_clf = [clf1, clf2, clf3]

#################################### Cross - Validation ####################################


print('10-fold cross validation:\n')
for clf, label in zip([clf1, clf2, clf3], clf_labels): #For all classifiers
    scores = cross_val_score(estimator=clf,  # estimate AUC based on cross validation
                             X=X_oversampled_1,
                             y=y_oversampled_1,
                             cv=10,
                             scoring='roc_auc')
    print("ROC AUC: %0.2f (+/- %0.2f) [%s]" # print peformance statistics based on cross-validation
#           % (scores.mean(), scores.std(), label))

##################################### Visualization ######################################

colors = [ 'orange', 'blue', 'green']      # colors for visualization
linestyles = [':', '--', '-.', '-']        # line styles for visualization
for clf, label, clr, ls in zip(all_clf,
               clf_labels, colors, linestyles):

    # Assuming the label of the positive class is 1 and data is normalized
    y_pred = clf.fit(X_train, y_train).predict_proba(X_test)[:, 1] # make predictions based on the classifiers

    fpr, tpr, thresholds = roc_curve(y_true=y_test,       # build ROC curve
                                     y_score=y_pred)
    roc_auc = auc(x=fpr, y=tpr)                           # compute Area Under the Curve (AUC)
    plt.plot(fpr, tpr,                                    # plot ROC Curve and create label with AUC values
             color=clr,
             linestyle=ls,
             label='%s (auc = %0.2f)' % (label, roc_auc))

plt.legend(loc='lower right')    # where to place the legend
plt.plot([0, 1], [0, 1],         # visualize random classifier
         linestyle='--',         # aesthetic parameters
         color='gray',
         linewidth=2)

plt.xlim([-0.1, 1.1])   #limits for x axis
plt.ylim([-0.1, 1.1])   #limits for y axis
plt.grid(alpha=0.5)
plt.xlabel('False positive rate (FPR)')
plt.ylabel('True positive rate (TPR)')


#plt.savefig('ROC_all_classifiers', dpi=300)
plt.show()

"""# Profit Graph"""

X_train = X_train.values
X_test = X_test.values
y_train = y_train.values
y_test = y_test.values

#Cost assumptions
'''Cost of FP: 1, cost of FN: 2, cost of TN: 0, cost of TP: -1'''
cost_TP = 0; cost_FP = -1; cost_FN = -100; cost_TN = 0;
cb_matrix = -1*np.array([[cost_TP, cost_FP],[cost_FN, cost_TN]])

#Convert to standard confusion matrix
def standard_confusion_matrix(y_true, y_predict):
    TP = sum((y_true == 1) & (y_predict == 1))
    TN = sum((y_true == 0) & (y_predict == 0))
    FP = sum((y_true == 0) & (y_predict == 1))
    FN = sum((y_true == 1) & (y_predict == 0))

    return np.array([[TP,FP],[FN,TN]])

# calculate profit curve
def profit_curve(cb, predict_probas, labels):
    #predict_probas = round(predict_probas,4)
    indices = np.argsort(predict_probas)
    sorted_probs = predict_probas[indices]
    sorted_labels = labels[indices]

    profit_list = []

    for sp, sl in zip(sorted_probs, sorted_labels):
        predict_labels = sorted_probs > sp + .0001
        conf_mat = standard_confusion_matrix(sorted_labels, predict_labels)
        profit_list.append((cb * conf_mat).sum() / float(len(labels)))
    return profit_list, sorted_probs

# Plot the profit curves
def plot_profit_curve(model, label, costbenefit, X_train, X_test, y_train, y_test, col):
    model.fit(X_train, y_train)
    predict_probas = model.predict_proba(X_test)[:,1]
    profit_list, sorted_probs = profit_curve(costbenefit, predict_probas, y_test)
    max_index = np.argmax(profit_list)
    max_threshold = sorted_probs[max_index]
    max_profit = profit_list[max_index]

    plt.plot(sorted_probs, profit_list, label=label, color=col, linewidth=3)
    plt.plot(max_threshold, max_profit, '.', color=col, markersize=18)

models = [clf1, clf2, clf3]
fig = plt.figure(figsize=(10,8))
# fig.set_facecolor('#F2F2F2')
colors = ['r', 'g', 'b']
for i, model in enumerate(models):
    plot_profit_curve(model, model.__class__.__name__, cb_matrix,
                      X_train, X_test, y_train, y_test, colors[i])
plt.title("Profit Curves")
plt.xlabel("Percentage of test instances (decreasing by score)")
plt.ylabel("Profit")
plt.legend(loc='lower right')
plt.savefig('Profit_curve.png', facecolor=fig.get_facecolor())
plt.show()